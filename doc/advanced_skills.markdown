# Diff-SVC(advanced skills)

## 0.前置知识

> svc：\
> Singing voice conversion，旨在保证歌唱内容的同时,将音色从source speaker转换到 target speaker

> mel：\
> 可简单认为，mel谱以数字格式保留了音频的所有信息；理想情况可完成wav→mel→wav的无损转换。

> hubert：\
> 语音内容编码器，可将音频wav编码为256维向量，任意语种经hubert编码为统一格式的数字内容（units），代替人工进行自动标注。

> 音色与发音习惯：\
> 音色可以理解为声音特征，发音习惯为个人特色的咬字、停顿等，共同构成音频的识别特征。\
> 需注意，svc模型完整的保留了咬字习惯，可能从听感上与源音频没有区别，不像目标特征，实际音色部分已经完整替换了。

> 音色泄露：\
> 模型工作流程为wav→units→wav。语音编码时，units不可避免的带入源音频音色信息，导致输出音频含有部分源音频的音色，称为音色泄露。

> [soft-vc](https://github.com/bshall/hubert/releases/download/v0.1/hubert-soft-0d54a1f4.pt): \
> hubert的一种，英文训练；soft-vc技术较普通hubert减少了音色泄露，不可避免的有内容信息损失，导致口胡（英文语料训练，其他语种出错率更高）\
> 此模型为默认模型，推荐使用。

> [cn_hubert](https://github.com/TencentGameMate/chinese_speech_pretrain):\
> 中文训练的hubert，音色、f0泄露更严重（不可直接变调），保留下来的语音信息也更完整（如发音、情感），通过特化解决。\
> 此模型（**本项目仅可使用base模型**）优缺点均较明显，**必须**配合特化操作弥补缺陷。

> 不准确的工作流程概括：\
> 将输入源wav编码为units（语音信息）并提取f0（音高）曲线参考，svc模型将units+f0转换为目标音色的mel、经过声码器转换为wav。\
> 预处理时，提取数据集mel、units、f0参数，模型在训练过程中学习到units+f0→mel的映射关系。\
> 推理时，提取输入源wav的units+f0，svc模型将两者转换为目标音色的mel，经声码器转换为所需wav。

## 1.特化
> [cn_hubert下载](https://github.com/TencentGameMate/chinese_speech_pretrain)\
> 模型放置路径：\
> "checkpoints/cn_hubert/chinese-hubert-base-fairseq-ckpt.pt"\
> 所需依赖 fairseq 请自行安装

> 理论:\
> units在理想情况仅包含语音内容，实际混入了音色、f0信息，模型训练中，实际学习到的是units（数据集音色、编码内容）+f0→mel（数据集音色、原内容）的映射关系。

> 流程：\
> 推理时完成的是，units（任意音色、数据集包含任意内容）+f0→mel（数据集音色、对应内容）的映射关系；因其与训练条件有偏差，应进行人工干预，即特化操作。

> 优缺点：\
> 特化旨在将any2one的模型，变为one2one，以固定输入音色为代价、更好的保留语音信息，即any→A变为B→A。

> 应用条件：\
> soft-vc模型自身包含音色泄露的解决方案，正常训练即可；cn_hubert推荐使用特化训练。

> 流程：\
> 目标音色为A，输入音色为B；以下使用的模型均为中文hubert的base模型\
> 1、以B为数据集（如opencpop）、正常流程训练svc模型\
> 2、将目标音色A的数据集，使用B模型转换一遍，得到A内容、B音色的wav数据集\
> 3、预先提取此数据集的units，得到A内容、B音色的units\
> 注：使用batch.py、units设为True、加载B模型，把A数据集（wav）放到batch文件夹内，会自动导出特化所需的units至batch文件夹（即2、3两步）\
> 4、将上步得到的units，与目标音色A的数据集放到同文件夹下，以正常流程进行训练\
> 5、程序检测到数据集中有npy格式的units会自动加载、不再临时提取\
> 6、特化训练即units（B音色、A编码内容）+f0→mel（A音色、A原内容）的映射关系，得到的模型仅允许B音色的音频输入、转换质量也会更高

> 推理：\
> 特化推理时完成的是，units（B音色、数据集包含任意内容）+f0→mel（A音色、对应内容）的映射关系，与训练条件更接近（均为B→A）\
> 所以特化模型可以解决音色泄露等问题，得到更高的转换质量

## 2.特化进阶

> 循环特化：\
> 特化训练可得B→A的高质量转换模型；同理，以此模型作为预模型导出units，可得A→B的特化模型\
> 重复多次后，A、B音色间的转换损耗越来越小，效果更佳

> 多项特化：\
> 可以分别使用B、C、D等音色炼制预模型\
> 将A数据集分为多份，分别导出A内容、BCD音色的数据集，进行特化训练\
> 由此得到B、C、D三种固定输入、A音色一种固定输出的特化模型（因输入条件更复杂、数据集数量需求更大）

> 音色抵抗：\
> 将数据集A拆为数份，使用不同音色units特化；此时可认为，模型进行了B、C、D三种音色的适应训练\
> 将数据集A复制数份，使用不同音色units特化；会出现下列特殊情况：\
> 1、X units、B音色 → X mel、A音色\
> 2、X units、C音色 → X mel、A音色\
> 3、X units、D音色 → X mel、A音色\
> 同一份内容X，有多种音色的units同时指向了同一份X mel;模型更容易总结出相同点（语义信息），忽略音色泄露的信息\
> 在音色种类足够时，这种特殊情况相对某几种音色的适应训练、更偏向于对陌生音色的抵抗训练，更加泛化